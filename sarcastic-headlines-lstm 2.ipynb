{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[](http://e7.pngegg.com/pngimages/360/846/png-clipart-human-behavior-thumb-homo-sapiens-sarcasm-logo-cartoon.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:10:31.855753Z",
     "iopub.status.busy": "2024-07-29T04:10:31.854809Z",
     "iopub.status.idle": "2024-07-29T04:10:37.358521Z",
     "shell.execute_reply": "2024-07-29T04:10:37.357511Z",
     "shell.execute_reply.started": "2024-07-29T04:10:31.855714Z"
    },
    "papermill": {
     "duration": 4.381801,
     "end_time": "2022-07-15T13:42:26.855359",
     "exception": false,
     "start_time": "2022-07-15T13:42:22.473558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "LIBRARIES WERE SUCCESFULLY IMPORTED...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model, metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import ensemble\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from xgboost import XGBClassifier\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from termcolor import colored\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import Word\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Dense,Dropout,Embedding,LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(print_changed_only = False)\n",
    "\n",
    "print(colored(\"\\nLIBRARIES WERE SUCCESFULLY IMPORTED...\", \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:10:37.361908Z",
     "iopub.status.busy": "2024-07-29T04:10:37.360906Z",
     "iopub.status.idle": "2024-07-29T04:10:37.589895Z",
     "shell.execute_reply": "2024-07-29T04:10:37.588961Z",
     "shell.execute_reply.started": "2024-07-29T04:10:37.361863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28614</th>\n",
       "      <td>1</td>\n",
       "      <td>jews to celebrate rosh hashasha or something</td>\n",
       "      <td>https://www.theonion.com/jews-to-celebrate-ros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28615</th>\n",
       "      <td>1</td>\n",
       "      <td>internal affairs investigator disappointed con...</td>\n",
       "      <td>https://local.theonion.com/internal-affairs-in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28616</th>\n",
       "      <td>0</td>\n",
       "      <td>the most beautiful acceptance speech this week...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/andrew-ah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28617</th>\n",
       "      <td>1</td>\n",
       "      <td>mars probe destroyed by orbiting spielberg-gat...</td>\n",
       "      <td>https://www.theonion.com/mars-probe-destroyed-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28618</th>\n",
       "      <td>1</td>\n",
       "      <td>dad clarifies this not a food stop</td>\n",
       "      <td>https://www.theonion.com/dad-clarifies-this-no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28619 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_sarcastic                                           headline  \\\n",
       "0                 1  thirtysomething scientists unveil doomsday clo...   \n",
       "1                 0  dem rep. totally nails why congress is falling...   \n",
       "2                 0  eat your veggies: 9 deliciously different recipes   \n",
       "3                 1  inclement weather prevents liar from getting t...   \n",
       "4                 1  mother comes pretty close to using word 'strea...   \n",
       "...             ...                                                ...   \n",
       "28614             1       jews to celebrate rosh hashasha or something   \n",
       "28615             1  internal affairs investigator disappointed con...   \n",
       "28616             0  the most beautiful acceptance speech this week...   \n",
       "28617             1  mars probe destroyed by orbiting spielberg-gat...   \n",
       "28618             1                 dad clarifies this not a food stop   \n",
       "\n",
       "                                            article_link  \n",
       "0      https://www.theonion.com/thirtysomething-scien...  \n",
       "1      https://www.huffingtonpost.com/entry/donna-edw...  \n",
       "2      https://www.huffingtonpost.com/entry/eat-your-...  \n",
       "3      https://local.theonion.com/inclement-weather-p...  \n",
       "4      https://www.theonion.com/mother-comes-pretty-c...  \n",
       "...                                                  ...  \n",
       "28614  https://www.theonion.com/jews-to-celebrate-ros...  \n",
       "28615  https://local.theonion.com/internal-affairs-in...  \n",
       "28616  https://www.huffingtonpost.com/entry/andrew-ah...  \n",
       "28617  https://www.theonion.com/mars-probe-destroyed-...  \n",
       "28618  https://www.theonion.com/dad-clarifies-this-no...  \n",
       "\n",
       "[28619 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('Sarcasm_Headlines_Dataset_v2.json', lines=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:10:41.312041Z",
     "iopub.status.busy": "2024-07-29T04:10:41.311119Z",
     "iopub.status.idle": "2024-07-29T04:10:41.320650Z",
     "shell.execute_reply": "2024-07-29T04:10:41.319667Z",
     "shell.execute_reply.started": "2024-07-29T04:10:41.312004Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['article_link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:10:41.934542Z",
     "iopub.status.busy": "2024-07-29T04:10:41.933667Z",
     "iopub.status.idle": "2024-07-29T04:10:41.958077Z",
     "shell.execute_reply": "2024-07-29T04:10:41.956807Z",
     "shell.execute_reply.started": "2024-07-29T04:10:41.934494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28619 entries, 0 to 28618\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   is_sarcastic  28619 non-null  int64 \n",
      " 1   headline      28619 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 447.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#get basic information about dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:10:42.744884Z",
     "iopub.status.busy": "2024-07-29T04:10:42.744182Z",
     "iopub.status.idle": "2024-07-29T04:10:42.763608Z",
     "shell.execute_reply": "2024-07-29T04:10:42.762692Z",
     "shell.execute_reply.started": "2024-07-29T04:10:42.744849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whether there are duplicated values\n",
    "# renaming the cols\n",
    "df.rename(columns={'is_sarcastic':'sarcas','headline':'text'},inplace=True)\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:10:43.359670Z",
     "iopub.status.busy": "2024-07-29T04:10:43.358746Z",
     "iopub.status.idle": "2024-07-29T04:10:43.379645Z",
     "shell.execute_reply": "2024-07-29T04:10:43.378786Z",
     "shell.execute_reply.started": "2024-07-29T04:10:43.359633Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop duplicated values from the dataset\n",
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:10:43.901353Z",
     "iopub.status.busy": "2024-07-29T04:10:43.900415Z",
     "iopub.status.idle": "2024-07-29T04:10:43.920665Z",
     "shell.execute_reply": "2024-07-29T04:10:43.919684Z",
     "shell.execute_reply.started": "2024-07-29T04:10:43.901310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e16fa_row0_col0 {\n",
       "  background-color: #ffff00;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e16fa_row1_col0 {\n",
       "  background-color: #ff0000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e16fa\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e16fa_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >sarcas</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e16fa_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e16fa_row0_col0\" class=\"data row0 col0\" >14951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e16fa_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e16fa_row1_col0\" class=\"data row1 col0\" >13552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d8adcdce50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the number of classes of the \"label\" variable of dataset\n",
    "df.groupby(\"sarcas\").count().style.background_gradient(cmap = \"autumn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016959,
     "end_time": "2022-07-15T13:42:27.63753",
     "exception": false,
     "start_time": "2022-07-15T13:42:27.620571",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='top'></a>\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<p style=\"background-color:#808000 ;font-family:arial;color:#FFFFFF;font-size:150%;text-align:center;border-radius:55px 1px;\">Preprocess the dataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:10:47.085833Z",
     "iopub.status.busy": "2024-07-29T04:10:47.085101Z",
     "iopub.status.idle": "2024-07-29T04:10:47.184104Z",
     "shell.execute_reply": "2024-07-29T04:10:47.183078Z",
     "shell.execute_reply.started": "2024-07-29T04:10:47.085796Z"
    },
    "papermill": {
     "duration": 0.196247,
     "end_time": "2022-07-15T13:42:27.850155",
     "exception": false,
     "start_time": "2022-07-15T13:42:27.653908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "CONVERTED SUCCESFULLY...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#convert uppercase letters to lowercase letters\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "\n",
    "print(colored(\"\\nCONVERTED SUCCESFULLY...\", \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:10:47.519970Z",
     "iopub.status.busy": "2024-07-29T04:10:47.519228Z",
     "iopub.status.idle": "2024-07-29T04:10:47.603663Z",
     "shell.execute_reply": "2024-07-29T04:10:47.602671Z",
     "shell.execute_reply.started": "2024-07-29T04:10:47.519935Z"
    },
    "papermill": {
     "duration": 0.289367,
     "end_time": "2022-07-15T13:42:28.15737",
     "exception": false,
     "start_time": "2022-07-15T13:42:27.868003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "DELETED PUNCTUATION MARKS SUCCESFULLY...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#delete punctuation marks\n",
    "\n",
    "df[\"text\"] = df[\"text\"].str.replace('[^\\w\\s]','')\n",
    "\n",
    "print(colored(\"\\nDELETED PUNCTUATION MARKS SUCCESFULLY...\", \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:10:48.095675Z",
     "iopub.status.busy": "2024-07-29T04:10:48.094783Z",
     "iopub.status.idle": "2024-07-29T04:10:48.155321Z",
     "shell.execute_reply": "2024-07-29T04:10:48.154310Z",
     "shell.execute_reply.started": "2024-07-29T04:10:48.095638Z"
    },
    "papermill": {
     "duration": 0.120096,
     "end_time": "2022-07-15T13:42:28.295856",
     "exception": false,
     "start_time": "2022-07-15T13:42:28.17576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      " NUMBERS DELETED SUCCESFULLY...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#delete numbers\n",
    "\n",
    "df[\"text\"] = df[\"text\"].str.replace('\\d','')\n",
    "\n",
    "print(colored(\"\\n NUMBERS DELETED SUCCESFULLY...\", \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:10:48.710113Z",
     "iopub.status.busy": "2024-07-29T04:10:48.709171Z",
     "iopub.status.idle": "2024-07-29T04:10:49.486398Z",
     "shell.execute_reply": "2024-07-29T04:10:49.485373Z",
     "shell.execute_reply.started": "2024-07-29T04:10:48.710073Z"
    },
    "papermill": {
     "duration": 1.10017,
     "end_time": "2022-07-15T13:42:29.414697",
     "exception": false,
     "start_time": "2022-07-15T13:42:28.314527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "STOPWORDS DELETED SUCCESFULLY...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#delete stopwords\n",
    "\n",
    "sw = stopwords.words(\"english\")\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n",
    "\n",
    "print(colored(\"\\nSTOPWORDS DELETED SUCCESFULLY...\", \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:10:50.827502Z",
     "iopub.status.busy": "2024-07-29T04:10:50.826896Z",
     "iopub.status.idle": "2024-07-29T04:10:55.007075Z",
     "shell.execute_reply": "2024-07-29T04:10:55.006079Z",
     "shell.execute_reply.started": "2024-07-29T04:10:50.827464Z"
    },
    "papermill": {
     "duration": 4.862033,
     "end_time": "2022-07-15T13:42:34.294067",
     "exception": false,
     "start_time": "2022-07-15T13:42:29.432034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "DONE SUCCESFULLY...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#lemmatization. That is, we get the roots of the words\n",
    "\n",
    "df[\"text_prc\"] = df[\"text\"].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "\n",
    "print(colored(\"\\nDONE SUCCESFULLY...\", \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:10:55.010796Z",
     "iopub.status.busy": "2024-07-29T04:10:55.010470Z",
     "iopub.status.idle": "2024-07-29T04:10:55.018830Z",
     "shell.execute_reply": "2024-07-29T04:10:55.017658Z",
     "shell.execute_reply.started": "2024-07-29T04:10:55.010766Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "def transform_text(text):\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "    \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "            \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    \n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:11:04.689599Z",
     "iopub.status.busy": "2024-07-29T04:11:04.689173Z",
     "iopub.status.idle": "2024-07-29T04:11:45.794450Z",
     "shell.execute_reply": "2024-07-29T04:11:45.793390Z",
     "shell.execute_reply.started": "2024-07-29T04:11:04.689566Z"
    }
   },
   "outputs": [],
   "source": [
    "df['stem_text'] = df['text_prc'].apply(transform_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:11:51.861398Z",
     "iopub.status.busy": "2024-07-29T04:11:51.860737Z",
     "iopub.status.idle": "2024-07-29T04:11:51.872914Z",
     "shell.execute_reply": "2024-07-29T04:11:51.871816Z",
     "shell.execute_reply.started": "2024-07-29T04:11:51.861353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sarcas</th>\n",
       "      <th>text</th>\n",
       "      <th>text_prc</th>\n",
       "      <th>stem_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>thirtysomething scientist unveil doomsday cloc...</td>\n",
       "      <td>thirtysometh scientist unveil doomsday clock h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails congress falling short ...</td>\n",
       "      <td>dem rep. totally nail congress falling short g...</td>\n",
       "      <td>dem total nail congress fall short gender raci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat veggies: 9 deliciously different recipes</td>\n",
       "      <td>eat veggies: 9 deliciously different recipe</td>\n",
       "      <td>eat veggi 9 delici differ recip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar getting work</td>\n",
       "      <td>inclement weather prevents liar getting work</td>\n",
       "      <td>inclement weather prevent liar get work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close using word 'streamin...</td>\n",
       "      <td>mother come pretty close using word 'streaming...</td>\n",
       "      <td>mother come pretti close use word correctli</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sarcas                                               text  \\\n",
       "0       1  thirtysomething scientists unveil doomsday clo...   \n",
       "1       0  dem rep. totally nails congress falling short ...   \n",
       "2       0       eat veggies: 9 deliciously different recipes   \n",
       "3       1       inclement weather prevents liar getting work   \n",
       "4       1  mother comes pretty close using word 'streamin...   \n",
       "\n",
       "                                            text_prc  \\\n",
       "0  thirtysomething scientist unveil doomsday cloc...   \n",
       "1  dem rep. totally nail congress falling short g...   \n",
       "2        eat veggies: 9 deliciously different recipe   \n",
       "3       inclement weather prevents liar getting work   \n",
       "4  mother come pretty close using word 'streaming...   \n",
       "\n",
       "                                           stem_text  \n",
       "0  thirtysometh scientist unveil doomsday clock h...  \n",
       "1  dem total nail congress fall short gender raci...  \n",
       "2                    eat veggi 9 delici differ recip  \n",
       "3            inclement weather prevent liar get work  \n",
       "4        mother come pretti close use word correctli  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:11:52.894104Z",
     "iopub.status.busy": "2024-07-29T04:11:52.893186Z",
     "iopub.status.idle": "2024-07-29T04:11:52.905799Z",
     "shell.execute_reply": "2024-07-29T04:11:52.904673Z",
     "shell.execute_reply.started": "2024-07-29T04:11:52.894065Z"
    },
    "papermill": {
     "duration": 0.032117,
     "end_time": "2022-07-15T13:42:34.486811",
     "exception": false,
     "start_time": "2022-07-15T13:42:34.454694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "DIVIDED SUCCESFULLY...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#divide the dataset into test and train sets\n",
    "\n",
    "x = df[\"stem_text\"]\n",
    "y = df[\"sarcas\"]\n",
    "\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(x, y,\n",
    "                                                                    test_size = 0.20,\n",
    "                                                                    shuffle = True,\n",
    "                                                                    random_state = 11)\n",
    "\n",
    "print(colored(\"\\nDIVIDED SUCCESFULLY...\", \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:11:55.568592Z",
     "iopub.status.busy": "2024-07-29T04:11:55.567849Z",
     "iopub.status.idle": "2024-07-29T04:11:55.573490Z",
     "shell.execute_reply": "2024-07-29T04:11:55.572477Z",
     "shell.execute_reply.started": "2024-07-29T04:11:55.568555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22802,) (5701,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017663,
     "end_time": "2022-07-15T13:42:34.522557",
     "exception": false,
     "start_time": "2022-07-15T13:42:34.504894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='top'></a>\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<p style=\"background-color:#808000 ;font-family:arial;color:#FFFFFF;font-size:150%;text-align:center;border-radius:55px 1px;\">Vectorize dataset with TFidfVectorizer method...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:11:58.537773Z",
     "iopub.status.busy": "2024-07-29T04:11:58.536947Z",
     "iopub.status.idle": "2024-07-29T04:11:58.541941Z",
     "shell.execute_reply": "2024-07-29T04:11:58.540920Z",
     "shell.execute_reply.started": "2024-07-29T04:11:58.537734Z"
    },
    "papermill": {
     "duration": 1.528419,
     "end_time": "2022-07-15T13:42:37.488835",
     "exception": false,
     "start_time": "2022-07-15T13:42:35.960416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf_idf_word_vectorizer = TfidfVectorizer(analyzer = \"word\")\n",
    "# tf_idf_word_vectorizer.fit(train_x)\n",
    "\n",
    "# x_train_tf_idf_word = tf_idf_word_vectorizer.transform(train_x)\n",
    "# x_test_tf_idf_word = tf_idf_word_vectorizer.transform(test_x)\n",
    "\n",
    "# x_train_tf_idf_word.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017817,
     "end_time": "2022-07-15T13:42:37.52757",
     "exception": false,
     "start_time": "2022-07-15T13:42:37.509753",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='top'></a>\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<p style=\"background-color:#808000 ;font-family:arial;color:#FFFFFF;font-size:150%;text-align:center;border-radius:55px 1px;\">Build machine learning models...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:12:01.114407Z",
     "iopub.status.busy": "2024-07-29T04:12:01.113725Z",
     "iopub.status.idle": "2024-07-29T04:12:01.119074Z",
     "shell.execute_reply": "2024-07-29T04:12:01.117847Z",
     "shell.execute_reply.started": "2024-07-29T04:12:01.114363Z"
    },
    "papermill": {
     "duration": 10.493848,
     "end_time": "2022-07-15T13:43:04.136278",
     "exception": false,
     "start_time": "2022-07-15T13:42:53.64243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# log = linear_model.LogisticRegression()\n",
    "# log_model = log.fit(x_train_tf_idf_word, train_y)\n",
    "# accuracy = model_selection.cross_val_score(log_model,\n",
    "#                                            x_test_tf_idf_word,\n",
    "#                                            test_y,\n",
    "#                                            cv = 20).mean()\n",
    "\n",
    "# print(\"\\nLogistic regression model with 'tf-idf' method\")\n",
    "# print(\"Accuracy ratio: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:12:01.732590Z",
     "iopub.status.busy": "2024-07-29T04:12:01.732177Z",
     "iopub.status.idle": "2024-07-29T04:12:01.737205Z",
     "shell.execute_reply": "2024-07-29T04:12:01.736183Z",
     "shell.execute_reply.started": "2024-07-29T04:12:01.732557Z"
    },
    "papermill": {
     "duration": 57.0603,
     "end_time": "2022-07-15T13:44:42.712353",
     "exception": false,
     "start_time": "2022-07-15T13:43:45.652053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xgb = XGBClassifier()\n",
    "# xgb_model = xgb.fit(x_train_tf_idf_word,train_y)\n",
    "# accuracy = model_selection.cross_val_score(xgb_model,\n",
    "#                                            x_test_tf_idf_word,\n",
    "#                                            test_y,\n",
    "#                                            cv = 20).mean()\n",
    "\n",
    "# print(\"\\nXGBoost model with 'tf-idf' method\")\n",
    "# print(\"Accuracy ratio: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<p style=\"background-color:#808000 ;font-family:arial;color:#FFFFFF;font-size:150%;text-align:center;border-radius:55px 1px;\">Build deep learning models...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:12:03.176755Z",
     "iopub.status.busy": "2024-07-29T04:12:03.176340Z",
     "iopub.status.idle": "2024-07-29T04:12:03.229396Z",
     "shell.execute_reply": "2024-07-29T04:12:03.228433Z",
     "shell.execute_reply.started": "2024-07-29T04:12:03.176720Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 22802/22802 [00:00<00:00, 278840.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unique_words = set()\n",
    "len_max = 0\n",
    "\n",
    "for sent in tqdm(train_x):\n",
    "    unique_words.update(sent)\n",
    "    \n",
    "    if(len_max<len(sent)):\n",
    "        len_max = len(sent)\n",
    "        \n",
    "print(len(list(unique_words)))\n",
    "print(len_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:12:07.645386Z",
     "iopub.status.busy": "2024-07-29T04:12:07.644967Z",
     "iopub.status.idle": "2024-07-29T04:12:08.494891Z",
     "shell.execute_reply": "2024-07-29T04:12:08.493862Z",
     "shell.execute_reply.started": "2024-07-29T04:12:07.645348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22802, 613) (5701, 613)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=len(list(unique_words)))\n",
    "tokenizer.fit_on_texts(list(train_x))\n",
    "\n",
    "train_x = tokenizer.texts_to_sequences(train_x)\n",
    "test_x = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "train_x = sequence.pad_sequences(train_x, maxlen=len_max)\n",
    "test_x = sequence.pad_sequences(test_x, maxlen=len_max)\n",
    "\n",
    "print(train_x.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer_lstm saved with joblib\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "import joblib\n",
    "\n",
    "joblib.dump(tokenizer, 'tokenizer_lstm.joblib')\n",
    "print(\"tokenizer_lstm saved with joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:12:09.511151Z",
     "iopub.status.busy": "2024-07-29T04:12:09.510764Z",
     "iopub.status.idle": "2024-07-29T04:12:09.516550Z",
     "shell.execute_reply": "2024-07-29T04:12:09.515427Z",
     "shell.execute_reply.started": "2024-07-29T04:12:09.511118Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(min_delta = 0.001, mode = \"auto\", verbose = 1,\n",
    "                               monitor = \"val_acc\",\n",
    "                               patience = 3)\n",
    "callbacks = [early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T13:53:22.732349Z",
     "iopub.status.busy": "2024-07-28T13:53:22.731906Z",
     "iopub.status.idle": "2024-07-28T13:53:22.737117Z",
     "shell.execute_reply": "2024-07-28T13:53:22.736125Z",
     "shell.execute_reply.started": "2024-07-28T13:53:22.732306Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(len(list(unique_words)), 100, input_length = len_max))\n",
    "# model.add(LSTM(64, dropout = 0.5, recurrent_dropout = 0.5, return_sequences = True))\n",
    "# model.add(Dense(25, activation = \"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1, activation = \"sigmoid\"))\n",
    "# model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = 0.0045),\n",
    "#               metrics = [\"accuracy\"])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:12:12.725641Z",
     "iopub.status.busy": "2024-07-29T04:12:12.725204Z",
     "iopub.status.idle": "2024-07-29T04:12:12.730156Z",
     "shell.execute_reply": "2024-07-29T04:12:12.729042Z",
     "shell.execute_reply.started": "2024-07-29T04:12:12.725601Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:12:17.361492Z",
     "iopub.status.busy": "2024-07-29T04:12:17.360333Z",
     "iopub.status.idle": "2024-07-29T04:12:17.365821Z",
     "shell.execute_reply": "2024-07-29T04:12:17.364828Z",
     "shell.execute_reply.started": "2024-07-29T04:12:17.361453Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = keras.Sequential([\n",
    "#     keras.layers.Embedding(len(list(unique_words)), 100, input_length=len_max),\n",
    "#     keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
    "#     keras.layers.Dense(24, activation='relu'),\n",
    "#     keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "# # compile model\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n",
    "# # model summary\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:12:18.167656Z",
     "iopub.status.busy": "2024-07-29T04:12:18.166759Z",
     "iopub.status.idle": "2024-07-29T04:12:18.171768Z",
     "shell.execute_reply": "2024-07-29T04:12:18.170688Z",
     "shell.execute_reply.started": "2024-07-29T04:12:18.167612Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# history = model.fit(train_x, train_y, epochs = 5, validation_data = (test_x, test_y), \n",
    "#                   batch_size = 16, verbose = 1, callbacks = callbacks)\n",
    "# history = model.fit(train_x, train_y,\n",
    "#                     epochs=5, verbose=1,\n",
    "#                     validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:12:19.081317Z",
     "iopub.status.busy": "2024-07-29T04:12:19.080350Z",
     "iopub.status.idle": "2024-07-29T04:12:19.085181Z",
     "shell.execute_reply": "2024-07-29T04:12:19.084208Z",
     "shell.execute_reply.started": "2024-07-29T04:12:19.081278Z"
    }
   },
   "outputs": [],
   "source": [
    "# history2 = model.fit(train_x, train_y, \n",
    "#                     epochs=10, verbose=1, \n",
    "#                     validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:12:19.696401Z",
     "iopub.status.busy": "2024-07-29T04:12:19.695990Z",
     "iopub.status.idle": "2024-07-29T04:12:19.701045Z",
     "shell.execute_reply": "2024-07-29T04:12:19.699936Z",
     "shell.execute_reply.started": "2024-07-29T04:12:19.696358Z"
    }
   },
   "outputs": [],
   "source": [
    "# history3 = model.fit(train_x, train_y, \n",
    "#                     epochs=50, verbose=1, \n",
    "#                     validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:12:20.608212Z",
     "iopub.status.busy": "2024-07-29T04:12:20.607821Z",
     "iopub.status.idle": "2024-07-29T04:12:20.612923Z",
     "shell.execute_reply": "2024-07-29T04:12:20.611882Z",
     "shell.execute_reply.started": "2024-07-29T04:12:20.608177Z"
    }
   },
   "outputs": [],
   "source": [
    "# epoch_num = range(1, len(history3.history[\"loss\"]) + 1)\n",
    "# plt.plot(epoch_num, history3.history[\"loss\"], \"r--\")\n",
    "# plt.plot(epoch_num, history3.history[\"val_loss\"], \"b-\")\n",
    "# plt.legend([\"Training loss\", \"Validation loss\"])\n",
    "# plt.xlabel(\"Epoch numbers\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:12:21.311306Z",
     "iopub.status.busy": "2024-07-29T04:12:21.310932Z",
     "iopub.status.idle": "2024-07-29T04:12:21.315924Z",
     "shell.execute_reply": "2024-07-29T04:12:21.314904Z",
     "shell.execute_reply.started": "2024-07-29T04:12:21.311274Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.save('LSTM.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:12:21.965120Z",
     "iopub.status.busy": "2024-07-29T04:12:21.964714Z",
     "iopub.status.idle": "2024-07-29T04:12:22.901485Z",
     "shell.execute_reply": "2024-07-29T04:12:22.900628Z",
     "shell.execute_reply.started": "2024-07-29T04:12:21.965083Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = 3000 # choose based on statistics\n",
    "oov_tok = ''\n",
    "embedding_dim = 100\n",
    "max_length = 200 # choose based on statistics, for example 150 to 200\n",
    "padding_type='post'\n",
    "trunc_type='post'\n",
    "\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(x, y,\n",
    "                                                                    test_size = 0.20,\n",
    "                                                                    shuffle = True,\n",
    "                                                                    random_state = 11)\n",
    "\n",
    "# tokenizer = Tokenizer(num_words=len(list(unique_words)))\n",
    "# tokenizer.fit_on_texts(list(train_x))\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size)\n",
    "tokenizer.fit_on_texts(list(train_x))\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "train_padded = sequence.pad_sequences(train_sequences, padding='post', maxlen=max_length)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "test_padded = sequence.pad_sequences(test_sequences, padding='post', maxlen=max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:12:27.934884Z",
     "iopub.status.busy": "2024-07-29T04:12:27.934508Z",
     "iopub.status.idle": "2024-07-29T04:12:31.185595Z",
     "shell.execute_reply": "2024-07-29T04:12:31.184500Z",
     "shell.execute_reply.started": "2024-07-29T04:12:27.934853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "model2 = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(64, \n",
    "                                                 kernel_regularizer=regularizers.l2(0.01))),  # Hanya regularizer L2 pada LSTM\n",
    "    # Menghapus salah satu Dropout layer\n",
    "    keras.layers.Dense(24, activation='relu'),  # Menghapus L2 regularization pada Dense layer\n",
    "    keras.layers.Dropout(0.3),  # Mengganti dropout rate dari 0.5 ke 0.3\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "               optimizer='adam',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:12:34.862998Z",
     "iopub.status.busy": "2024-07-29T04:12:34.862099Z",
     "iopub.status.idle": "2024-07-29T04:15:38.711479Z",
     "shell.execute_reply": "2024-07-29T04:15:38.710299Z",
     "shell.execute_reply.started": "2024-07-29T04:12:34.862959Z"
    }
   },
   "outputs": [],
   "source": [
    "#num_epochs = 5\n",
    "#history_ex = model2.fit(train_padded, train_y, \n",
    "  #                  epochs=num_epochs, verbose=1, \n",
    "   #                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 194ms/step - accuracy: 0.6310 - loss: 1.2636 - val_accuracy: 0.7814 - val_loss: 0.4691\n",
      "Epoch 2/5\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.8153 - loss: 0.4294"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved at epoch 2\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 190ms/step - accuracy: 0.8153 - loss: 0.4295 - val_accuracy: 0.7781 - val_loss: 0.4730\n",
      "Epoch 3/5\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 197ms/step - accuracy: 0.8381 - loss: 0.3919 - val_accuracy: 0.7827 - val_loss: 0.4613\n",
      "Epoch 4/5\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 216ms/step - accuracy: 0.8659 - loss: 0.3404 - val_accuracy: 0.7779 - val_loss: 0.4805\n",
      "Epoch 5/5\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 222ms/step - accuracy: 0.8731 - loss: 0.3248 - val_accuracy: 0.7748 - val_loss: 0.5247\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "class SaveAtEpoch(Callback):\n",
    "    def __init__(self, save_epoch, save_path):\n",
    "        super(SaveAtEpoch, self).__init__()\n",
    "        self.save_epoch = save_epoch\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch + 1 == self.save_epoch:\n",
    "            self.model.save(self.save_path, save_format='keras')\n",
    "            print(f\"\\nModel saved at epoch {self.save_epoch}\")\n",
    "\n",
    "# Inisialisasi callback\n",
    "save_at_epoch_2 = SaveAtEpoch(save_epoch=2, save_path='LSTM_MODEL_SARCASM.keras')\n",
    "\n",
    "# Train the model and save at epoch 2\n",
    "history_ex = model2.fit(train_padded, train_y, \n",
    "                        epochs=num_epochs, \n",
    "                        validation_split=0.2, \n",
    "                        verbose=1, \n",
    "                        callbacks=[save_at_epoch_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model saved at epoch 2\n",
    "best_model_epoch_2 = load_model('LSTM_MODEL_SARCASM.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 59ms/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step\n",
      "Training Accuracy (Epoch 2): 0.8361\n",
      "Training Precision (Epoch 2): 0.8233\n",
      "Training Recall (Epoch 2): 0.8351\n",
      "Training F1-score (Epoch 2): 0.8292\n",
      "Testing Accuracy (Epoch 2): 0.7692\n",
      "Testing Precision (Epoch 2): 0.7495\n",
      "Testing Recall (Epoch 2): 0.7674\n",
      "Testing F1-score (Epoch 2): 0.7584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Dapatkan prediksi untuk data training dan testing\n",
    "train_predictions_epoch_2 = (best_model_epoch_2.predict(train_padded) > 0.5).astype(\"int32\")\n",
    "test_predictions_epoch_2 = (best_model_epoch_2.predict(test_padded) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Menghitung metrik pada data training\n",
    "train_accuracy_epoch_2 = accuracy_score(train_y, train_predictions_epoch_2)\n",
    "train_precision_epoch_2 = precision_score(train_y, train_predictions_epoch_2)\n",
    "train_recall_epoch_2 = recall_score(train_y, train_predictions_epoch_2)\n",
    "train_f1_epoch_2 = f1_score(train_y, train_predictions_epoch_2)\n",
    "\n",
    "# Menghitung metrik pada data testing\n",
    "test_accuracy_epoch_2 = accuracy_score(test_y, test_predictions_epoch_2)\n",
    "test_precision_epoch_2 = precision_score(test_y, test_predictions_epoch_2)\n",
    "test_recall_epoch_2 = recall_score(test_y, test_predictions_epoch_2)\n",
    "test_f1_epoch_2 = f1_score(test_y, test_predictions_epoch_2)\n",
    "\n",
    "# Cetak hasilnya\n",
    "print(f\"Training Accuracy (Epoch 2): {train_accuracy_epoch_2:.4f}\")\n",
    "print(f\"Training Precision (Epoch 2): {train_precision_epoch_2:.4f}\")\n",
    "print(f\"Training Recall (Epoch 2): {train_recall_epoch_2:.4f}\")\n",
    "print(f\"Training F1-score (Epoch 2): {train_f1_epoch_2:.4f}\")\n",
    "\n",
    "print(f\"Testing Accuracy (Epoch 2): {test_accuracy_epoch_2:.4f}\")\n",
    "print(f\"Testing Precision (Epoch 2): {test_precision_epoch_2:.4f}\")\n",
    "print(f\"Testing Recall (Epoch 2): {test_recall_epoch_2:.4f}\")\n",
    "print(f\"Testing F1-score (Epoch 2): {test_f1_epoch_2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T04:15:45.113798Z",
     "iopub.status.busy": "2024-07-29T04:15:45.113399Z",
     "iopub.status.idle": "2024-07-29T04:15:45.118262Z",
     "shell.execute_reply": "2024-07-29T04:15:45.117217Z",
     "shell.execute_reply.started": "2024-07-29T04:15:45.113763Z"
    }
   },
   "outputs": [],
   "source": [
    "# history_ex2 = model2.fit(train_padded, train_y, \n",
    "#                     epochs=10, verbose=1, \n",
    "#                     validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow==2.9.0 (from versions: 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0)\n",
      "ERROR: No matching distribution found for tensorflow==2.9.0\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==2.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 30764,
     "sourceId": 533474,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30209,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
